{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "<br>\n", " Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.<br>\n", " Licensed under the Apache License, Version 2.0 (the \"License\");<br>\n", " you may not use this file except in compliance with the License.<br>\n", " You may obtain a copy of the License at<br>\n", "<br>\n", "     http://www.apache.org/licenses/LICENSE-2.0<br>\n", "<br>\n", " Unless required by applicable law or agreed to in writing, software<br>\n", " distributed under the License is distributed on an \"AS IS\" BASIS,<br>\n", " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>\n", " See the License for the specific language governing permissions and<br>\n", " limitations under the License.<br>\n", "<br>\n", "#########################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import json\n", "import os\n", "import torch\n", "from torch.utils.data import DataLoader\n", "import ast"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from flowtron import FlowtronLoss\n", "from flowtron import Flowtron\n", "from data import Data, DataCollate\n", "from flowtron_logger import FlowtronLogger"]}, {"cell_type": "markdown", "metadata": {}, "source": ["====START: ADDED FOR DISTRIBUTED======"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from distributed import init_distributed, apply_gradient_allreduce, reduce_tensor\n", "from torch.utils.data.distributed import DistributedSampler\n", "#=====END:   ADDED FOR DISTRIBUTED======"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def update_params(config, params):\n", "    for param in params:\n", "        print(param)\n", "        k, v = param.split(\"=\")\n", "        try:\n", "            v = ast.literal_eval(v)\n", "        except:\n", "            pass\n", "        k_split = k.split('.')\n", "        if len(k_split) > 1:\n", "            parent_k = k_split[0]\n", "            cur_param = ['.'.join(k_split[1:])+\"=\"+str(v)]\n", "            update_params(config[parent_k], cur_param)\n", "        elif k in config and len(k_split) == 1:\n", "            config[k] = v\n", "        else:\n", "            print(\"{}, {} params not updated\".format(k, v))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prepare_dataloaders(data_config, n_gpus, batch_size):\n", "    # Get data, data loaders and collate function ready\n", "    ignore_keys = ['training_files', 'validation_files']\n", "    trainset = Data(data_config['training_files'],\n", "                    **dict((k, v) for k, v in data_config.items()\n", "                    if k not in ignore_keys))\n", "    valset = Data(data_config['validation_files'],\n", "                **dict((k, v) for k, v in data_config.items()\n", "                if k not in ignore_keys), speaker_ids=trainset.speaker_ids,\n", "                emotion_ids=trainset.emotion_ids)\n", "    collate_fn = DataCollate()\n", "    train_sampler, shuffle = None, True\n", "    if n_gpus > 1:\n", "        train_sampler, shuffle = DistributedSampler(trainset), False\n", "    train_loader = DataLoader(trainset, num_workers=1, shuffle=shuffle,\n", "                              sampler=train_sampler, batch_size=batch_size,\n", "                              pin_memory=False, drop_last=True,\n", "                              collate_fn=collate_fn)\n", "    return train_loader, valset, collate_fn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def warmstart(checkpoint_path, model, include_layers=None):\n", "    print(\"Warm starting model\", checkpoint_path)\n", "    pretrained_dict = torch.load(checkpoint_path, map_location='cpu')\n", "    if 'model' in pretrained_dict:\n", "        pretrained_dict = pretrained_dict['model'].state_dict()\n", "    else:\n", "        pretrained_dict = pretrained_dict['state_dict']\n", "    if include_layers is not None:\n", "        pretrained_dict = {k: v for k, v in pretrained_dict.items()\n", "                           if any(l in k for l in include_layers)}\n", "    model_dict = model.state_dict()\n", "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n", "                       if k in model_dict}\n", "    if pretrained_dict['speaker_embedding.weight'].shape != model_dict['speaker_embedding.weight'].shape:\n", "        del pretrained_dict['speaker_embedding.weight']\n", "    model_dict.update(pretrained_dict)\n", "    model.load_state_dict(model_dict)\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_checkpoint(checkpoint_path, model, optimizer, ignore_layers=[]):\n", "    assert os.path.isfile(checkpoint_path)\n", "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n", "    iteration = checkpoint_dict['iteration']\n", "    model_dict = checkpoint_dict['model'].state_dict()\n", "    if len(ignore_layers) > 0:\n", "        model_dict = {k: v for k, v in model_dict.items()\n", "                      if k not in ignore_layers}\n", "        dummy_dict = model.state_dict()\n", "        dummy_dict.update(model_dict)\n", "        model_dict = dummy_dict\n", "    else:\n", "        optimizer.load_state_dict(checkpoint_dict['optimizer'])\n", "    model.load_state_dict(model_dict)\n", "    print(\"Loaded checkpoint '{}' (iteration {})\" .format(\n", "          checkpoint_path, iteration))\n", "    return model, optimizer, iteration"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_checkpoint(model, optimizer, learning_rate, iteration, filepath):\n", "    print(\"Saving model and optimizer state at iteration {} to {}\".format(\n", "          iteration, filepath))\n", "    model_for_saving = Flowtron(**model_config)\n", "    model_for_saving.load_state_dict(model.state_dict())\n", "    torch.save({'model': model_for_saving,\n", "                'iteration': iteration,\n", "                'optimizer': optimizer.state_dict(),\n", "                'learning_rate': learning_rate}, filepath)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_validation_loss(model, criterion, valset, collate_fn, batch_size,\n", "                            n_gpus):\n", "    model.eval()\n", "    with torch.no_grad():\n", "        val_sampler = DistributedSampler(valset) if n_gpus > 1 else None\n", "        val_loader = DataLoader(valset, sampler=val_sampler, num_workers=1,\n", "                                shuffle=False, batch_size=batch_size,\n", "                                pin_memory=False, collate_fn=collate_fn)\n", "        val_loss = 0.0\n", "        for i, batch in enumerate(val_loader):\n", "            mel, speaker_vecs, emotion_vecs, text, in_lens, out_lens, gate_target = batch\n", "            mel, speaker_vecs, emotion_vecs, text = mel, speaker_vecs, emotion_vecs, text\n", "            in_lens, out_lens, gate_target = in_lens, out_lens, gate_target\n", "            z, log_s_list, gate_pred, attn, mean, log_var, prob = model(\n", "                mel, speaker_vecs, emotion_vecs, text, in_lens, out_lens)\n", "            loss = criterion((z, log_s_list, gate_pred, mean, log_var, prob),\n", "                             gate_target, out_lens)\n", "            if n_gpus > 1:\n", "                reduced_val_loss = reduce_tensor(loss.data, n_gpus).item()\n", "            else:\n", "                reduced_val_loss = loss.item()\n", "            val_loss += reduced_val_loss\n", "        val_loss = val_loss / (i + 1)\n", "    print(\"Mean {}\\nLogVar {}\\nProb {}\".format(mean, log_var, prob))\n", "    model.train()\n", "    return val_loss, attn, gate_pred, gate_target"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(n_gpus, rank, output_directory, epochs, learning_rate, weight_decay,\n", "          sigma, iters_per_checkpoint, batch_size, seed, checkpoint_path,\n", "          ignore_layers, include_layers, warmstart_checkpoint_path,\n", "          with_tensorboard, fp16_run):\n", "    torch.manual_seed(seed)\n", "    torch.cuda.manual_seed(seed)\n", "    if n_gpus > 1:\n", "        init_distributed(rank, n_gpus, **dist_config)\n", "    criterion = FlowtronLoss(sigma, model_config['n_components'] > 1,\n", "                             model_config['use_gate_layer'])\n", "    model = Flowtron(**model_config)\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n", "                                 weight_decay=weight_decay)\n\n", "    # Load checkpoint if one exists\n", "    iteration = 0\n", "    if warmstart_checkpoint_path != \"\":\n", "        model = warmstart(warmstart_checkpoint_path, model, include_layers)\n", "    if checkpoint_path != \"\":\n", "        model, optimizer, iteration = load_checkpoint(checkpoint_path, model,\n", "                                                      optimizer, ignore_layers)\n", "        iteration += 1  # next iteration is iteration + 1\n", "    if n_gpus > 1:\n", "        model = apply_gradient_allreduce(model)\n", "    print(model)\n", "    if fp16_run:\n", "        from apex import amp\n", "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n", "    train_loader, valset, collate_fn = prepare_dataloaders(\n", "        data_config, n_gpus, batch_size)\n\n", "    # Get shared output_directory ready\n", "    if rank == 0 and not os.path.isdir(output_directory):\n", "        os.makedirs(output_directory)\n", "        os.chmod(output_directory, 0o775)\n", "    print(\"output directory\", output_directory)\n", "    if with_tensorboard and rank == 0:\n", "        logger = FlowtronLogger(os.path.join(output_directory, 'logs'))\n", "    model.train()\n", "    epoch_offset = max(0, int(iteration / len(train_loader)))\n", "    # ================ MAIN TRAINNIG LOOP! ===================\n", "    for epoch in range(epoch_offset, epochs):\n", "        print(\"Epoch: {}\".format(epoch))\n", "        for batch in train_loader:\n", "            model.zero_grad()\n", "            mel, speaker_vecs, emotion_vecs, text, in_lens, out_lens, gate_target = batch\n", "            mel, speaker_vecs, emotion_vecs, text = mel, speaker_vecs, emotion_vecs, text\n", "            in_lens, out_lens, gate_target = in_lens, out_lens, gate_target\n", "            z, log_s_list, gate_pred, attn, mean, log_var, prob = model(\n", "                mel, speaker_vecs, emotion_vecs, text, in_lens, out_lens)\n", "            loss = criterion((z, log_s_list, gate_pred, mean, log_var, prob),\n", "                             gate_target, out_lens)\n", "            if n_gpus > 1:\n", "                reduced_loss = reduce_tensor(loss.data, n_gpus).item()\n", "            else:\n", "                reduced_loss = loss.item()\n", "            if fp16_run:\n", "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n", "                    scaled_loss.backward()\n", "            else:\n", "                loss.backward()\n", "            optimizer.step()\n", "            if rank == 0:\n", "                print(\"{}:\\t{:.9f}\".format(iteration, reduced_loss), flush=True)\n", "            if with_tensorboard and rank == 0:\n", "                logger.add_scalar('training_loss', reduced_loss, iteration)\n", "                logger.add_scalar('learning_rate', learning_rate, iteration)\n", "            if (iteration % iters_per_checkpoint == 0):\n", "                val_loss, attns, gate_pred, gate_target = compute_validation_loss(\n", "                    model, criterion, valset, collate_fn, batch_size, n_gpus)\n", "                if rank == 0:\n", "                    print(\"Validation loss {}: {:9f}  \".format(iteration, val_loss))\n", "                    if with_tensorboard:\n", "                        logger.log_validation(\n", "                            val_loss, attns, gate_pred, gate_target, iteration)\n", "                    checkpoint_path = \"{}/model_{}\".format(\n", "                        output_directory, iteration)\n", "                    save_checkpoint(model, optimizer, learning_rate, iteration,\n", "                                    checkpoint_path)\n", "            iteration += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    parser = argparse.ArgumentParser()\n", "    parser.add_argument('-c', '--config', type=str,\n", "                        help='JSON file for configuration')\n", "    parser.add_argument('-p', '--params', nargs='+', default=[])\n", "    args = parser.parse_args()\n", "    args.rank = 0\n\n", "    # Parse configs.  Globals nicer in this case\n", "    with open(args.config) as f:\n", "        data = f.read()\n", "    global config\n", "    config = json.loads(data)\n", "    update_params(config, args.params)\n", "    print(config)\n", "    train_config = config[\"train_config\"]\n", "    global data_config\n", "    data_config = config[\"data_config\"]\n", "    global dist_config\n", "    dist_config = config[\"dist_config\"]\n", "    global model_config\n", "    model_config = config[\"model_config\"]\n\n", "    # Make sure the launcher sets `RANK` and `WORLD_SIZE`.\n", "    rank = int(os.getenv('RANK', '0'))\n", "    n_gpus = int(os.getenv(\"WORLD_SIZE\", '1'))\n", "    print('> got rank {} and world size {} ...'.format(rank, n_gpus))\n", "    if n_gpus == 1 and rank != 0:\n", "        raise Exception(\"Doing single GPU training on rank > 0\")\n", "    torch.backends.cudnn.enabled = True\n", "    torch.backends.cudnn.benchmark = False\n", "    train(n_gpus, rank, **train_config)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}